# CADL1: Preprocessing Steps
# Import libraries
import nltk
import spacy
import string
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer

# Download NLTK resources (run once)
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Sample text corpus
corpus = [
    "Students are learning Python programming to build real-world applications.",
    "Electric vehicles are becoming popular due to rising fuel prices and environmental concerns.",
    "Online shopping platforms are using recommendation systems to improve customer experience."
]

# Tokenization + Lowercasing + Removing punctuation
print("ðŸ”¹ Tokenization + Normalization")
for text in corpus:
    tokens = word_tokenize(text.lower())  # lowercase
    tokens = [w for w in tokens if w not in string.punctuation]  # remove punctuation
    print(f"Original: {text}")
    print(f"Tokens: {tokens}\n")

# Stopword removal (NLTK)
stop_words = set(stopwords.words('english'))
print("ðŸ”¹ Stopword Removal")
for text in corpus:
    tokens = word_tokenize(text.lower())
    tokens = [w for w in tokens if w not in string.punctuation]
    filtered = [w for w in tokens if w not in stop_words]
    print(f"Filtered Tokens: {filtered}\n")

# Stemming (NLTK - PorterStemmer)
ps = PorterStemmer()
print("ðŸ”¹ Stemming")
for text in corpus:
    tokens = word_tokenize(text.lower())
    tokens = [w for w in tokens if w not in string.punctuation]
    stemmed = [ps.stem(w) for w in tokens]
    print(f"Stemmed: {stemmed}\n")

# Lemmatization (NLTK - WordNetLemmatizer)
lemmatizer = WordNetLemmatizer()
print("ðŸ”¹ Lemmatization (NLTK)")
for text in corpus:
    tokens = word_tokenize(text.lower())
    tokens = [w for w in tokens if w not in string.punctuation]
    lemmatized = [lemmatizer.lemmatize(w) for w in tokens]
    print(f"Lemmatized: {lemmatized}\n")

# Lemmatization with spaCy
nlp = spacy.load("en_core_web_sm")
print("ðŸ”¹ Lemmatization with spaCy")
for text in corpus:
    doc = nlp(text.lower())
    lemmas = [token.lemma_ for token in doc if token.text not in string.punctuation]
    print(f"spaCy Lemmas: {lemmas}\n")
